{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drmcoelho/APILLMML/blob/main/multimodal_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8271152d"
      },
      "id": "8271152d",
      "cell_type": "markdown",
      "source": [
        "# üöÄ Etapa 0: Estrutura e Roadmap Interativo\n",
        "\n",
        "> **Vis√£o Geral:**  \n",
        "> Nesta etapa inicial, definimos de forma detalhada toda a organiza√ß√£o das etapas subsequentes. Use o sum√°rio clic√°vel para navegar e prepare-se para uma jornada de desenvolvimento multimodal robusta.\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "<summary><strong>üìë Sum√°rio Interativo</strong></summary>\n",
        "\n",
        "1. [Etapa 1: Montagem de Ambiente & Seguran√ßa](#etapa-1-montagem-de-ambiente--seguranca)  \n",
        "2. [Etapa 2: Sele√ß√£o e Ingest√£o de PDFs](#etapa-2-selecao-e-ingestao-de-pdfs)  \n",
        "3. [Etapa 3: Extra√ß√£o Avan√ßada de Texto](#etapa-3-extracao-avancada-de-texto)  \n",
        "4. [Etapa 4: An√°lise Explorat√≥ria Cl√≠nica](#etapa-4-analise-exploratoria-clinica)  \n",
        "5. [Etapa 5: Pr√©-processamento & Tokeniza√ß√£o](#etapa-5-pre-processamento--tokenizacao)  \n",
        "6. [Etapa 6: Constru√ß√£o de Dados Multimodal](#etapa-6-construcao-de-dados-multimodal)  \n",
        "7. [Etapa 7: Modelos Candidatos & Hyperparams](#etapa-7-modelos-candidatos--hyperparams)  \n",
        "8. [Etapa 8: Treinamento Avan√ßado](#etapa-8-treinamento-avancado)  \n",
        "9. [Etapa 9: Avalia√ß√£o Cl√≠nica Especializada](#etapa-9-avaliacao-clinica-especializada)  \n",
        "10. [Etapa 10: Exporta√ß√£o do Modelo √ìtimo](#etapa-10-exportacao-do-modelo-otimo)  \n",
        "11. [Etapa 11: Deploy & Cloud-Burst](#etapa-11-deploy--cloud-burst)  \n",
        "12. [Etapa 12: Monitoramento & Atualiza√ß√£o](#etapa-12-monitoramento--atualizacao)  \n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Roadmap em 3 N√≠veis\n",
        "\n",
        "| Fase           | Objetivo Principal                                          | Dura√ß√£o       |\n",
        "|:--------------:|:------------------------------------------------------------|:-------------:|\n",
        "| **B√°sico**     | PDF ‚Üí Texto ‚Üí Fine-tune inicial                             | 1‚Äì2 dias      |\n",
        "| **Intermedi√°rio**| Imagens & √Åudio ‚Üí Fusion multimodal                       | 2 semanas     |\n",
        "| **Avan√ßado**   | Seguran√ßa, Compliance, Deploy, Monitoramento                | 1 semana      |\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Cheatsheet R√°pida\n",
        "\n",
        "| Componente                | Comando/Refer√™ncia                            | Notas R√°pidas                                           |\n",
        "|:-------------------------:|:-----------------------------------------------|:--------------------------------------------------------|\n",
        "| Montar Drive              | `drive.mount('/content/drive')`                | Use `force_remount=True` para atualizar montagem        |\n",
        "| Extra√ß√£o (PyMuPDF)        | `fitz.open(...).get_text(\"text\")`              | Mais r√°pido que pdfminer                                |\n",
        "| Tokeniza√ß√£o (Clinical)    | `AutoTokenizer.from_pretrained(...)`           | Modelos Bio_ClinicalBERT, etc.                          |\n",
        "| Mixed Precision           | `TrainingArguments(fp16=True, bf16=True)`      | Habilitar BF16 em Colab Pro                             |\n",
        "| DVC Data/Model Versioning | `dvc run -n step ...`                          | Reprodutibilidade completa                              |\n",
        "| PHI Detection             | `spaCy EntityRuler` + regex                    | Redirecionar logs para `/mnt/data/logs`                 |\n"
      ]
    },
    {
      "metadata": {
        "id": "88139ce6"
      },
      "id": "88139ce6",
      "cell_type": "markdown",
      "source": [
        "# üåü Introdu√ß√£o Mega Robusta\n",
        "\n",
        "Este notebook guia voc√™ em um **pipeline multimodal** de aprendizado profundo para **medicina**, desde a ingest√£o de PDFs at√© o **deploy** de um modelo cl√≠nico, com:\n",
        "\n",
        "- **Cheatsheets** e **dicas de mestre** para acelerar o desenvolvimento.\n",
        "- **Tabelas de refer√™ncia** para consulta imediata.\n",
        "- **Widgets interativos** e **visualiza√ß√µes avan√ßadas**.\n",
        "- **Seguran√ßa** e **compliance** (HIPAA/GDPR) embutidos.\n",
        "- **Estrat√©gia de cache** para reutiliza√ß√£o de dados entre sess√µes.\n",
        "\n",
        "Prepare-se para uma experi√™ncia de codifica√ß√£o **robusta**, **inovadora** e **produtiva**!\n"
      ]
    },
    {
      "metadata": {
        "id": "3e826d1a"
      },
      "id": "3e826d1a",
      "cell_type": "markdown",
      "source": [
        "## Etapa 1: Montagem de Ambiente & Seguran√ßa\n",
        "\n",
        "Nesta etapa, configuramos o ambiente **Google Colab Pro**, instalamos depend√™ncias com cache, configuramos `accelerate`, gerenciamos segredos via vari√°veis de ambiente nativas do Colab com fallback interativo, fazemos login no **Weights & Biases** automaticamente e criamos diret√≥rios de cache.\n"
      ]
    },
    {
      "source": [
        "import os, json\n",
        "import torch\n",
        "from google.colab import drive\n",
        "import wandb\n",
        "from getpass import getpass\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# --- Parte de Configura√ß√£o de Ambiente ---\n",
        "\n",
        "# 1. Verificar GPU & Mem√≥ria\n",
        "print(\"‚è≥ Verificando recursos de hardware...\")\n",
        "if 'COLAB_GPU' not in os.environ or not torch.cuda.is_available():\n",
        "    raise EnvironmentError(\"Por favor, selecione Runtime > Change runtime type > GPU e High-RAM.\")\n",
        "print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}, Mem√≥ria Aproximada: ~25GB\")\n",
        "\n",
        "# 2. Montar Google Drive\n",
        "print(\"‚è≥ Montando Google Drive...\")\n",
        "try:\n",
        "    # Tenta montar sem for√ßar a remontagem primeiro\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"‚úÖ Google Drive montado ou j√° conectado.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Falha na montagem inicial ({e}). Tentando for√ßar remontagem...\")\n",
        "    try:\n",
        "        # Se falhar, tenta for√ßar a remontagem\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"‚úÖ Google Drive remontado com sucesso.\")\n",
        "    except Exception as e_force:\n",
        "        # Se a remontagem for√ßada tamb√©m falhar, exibe um erro cr√≠tico\n",
        "        print(f\"‚ùå Falha cr√≠tica ao montar Google Drive: {e_force}\")\n",
        "        raise RuntimeError(\"Falha na montagem do Google Drive. A execu√ß√£o n√£o pode continuar.\")\n",
        "\n",
        "# Definindo o caminho base para os dados no Drive\n",
        "DATA_ROOT = '/content/drive/MyDrive/med-llm/data'\n",
        "# Definindo o subdiret√≥rio para PDFs raw\n",
        "PDF_ROOT = f\"{DATA_ROOT}/raw/pdfs\"\n",
        "# Cria o diret√≥rio base de dados se ele n√£o existir\n",
        "os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "print(\"üìÇ Caminho raiz dos dados (DATA_ROOT):\", DATA_ROOT)\n",
        "\n",
        "# 3. Criar Diret√≥rios de Cache\n",
        "# Criando diret√≥rios para armazenar dados intermedi√°rios e modelos.\n",
        "# Utilizar /content para cache local pode ser mais r√°pido que no Drive para arquivos tempor√°rios,\n",
        "# mas pode n√£o persistir entre sess√µes se a inst√¢ncia do Colab for reciclada.\n",
        "# Os diret√≥rios em /mnt/data s√£o frequentemente usados por bibliotecas como accelerate.\n",
        "dirs_to_create = ['/content/data/pdf_texts', '/content/data/datasets', '/content/data/models']\n",
        "# Garante que o diret√≥rio pai /content/data existe antes de criar os subdiret√≥rios\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "for d in dirs_to_create:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "print(\"‚úÖ Diret√≥rios de cache locais criados/verificados:\", dirs_to_create)\n",
        "# Nota: Se voc√™ precisa persist√™ncia do cache entre sess√µes, considere usar o Drive.\n",
        "\n",
        "# --- Parte de Gerenciamento de Segredos ---\n",
        "\n",
        "# Caminho para o arquivo JSON que armazenar√° os segredos no Google Drive\n",
        "SECRETS_PATH = '/content/drive/MyDrive/secrets.json'\n",
        "\n",
        "def load_secrets(path):\n",
        "    \"\"\"Carrega segredos de um arquivo JSON.\"\"\"\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        # Retorna um dicion√°rio vazio se o arquivo n√£o existir ou for inv√°lido\n",
        "        return {}\n",
        "\n",
        "def save_secrets(secrets, path):\n",
        "    \"\"\"Salva segredos em um arquivo JSON com permiss√µes restritas.\"\"\"\n",
        "    # Abre o arquivo com permiss√µes de leitura/escrita apenas para o propriet√°rio (0o600)\n",
        "    # O_WRONLY: Abre para escrita apenas\n",
        "    # O_CREAT: Cria o arquivo se n√£o existir\n",
        "    # O_TRUNC: Trunca o arquivo para comprimento zero se ele existir\n",
        "    # 0o600: Permiss√µes octais (rw-------)\n",
        "    fd = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)\n",
        "    with os.fdopen(fd, 'w') as f:\n",
        "        json.dump(secrets, f, indent=4) # Use indent para formata√ß√£o leg√≠vel\n",
        "\n",
        "# Carrega os segredos existentes do arquivo no Drive\n",
        "secrets = load_secrets(SECRETS_PATH)\n",
        "required_keys = ['HF_TOKEN', 'WANDB_API_KEY', 'UMLS_API_KEY']\n",
        "\n",
        "# Solicita as chaves ausentes ou vazias interativamente\n",
        "print(\"üîë Verificando e configurando segredos...\")\n",
        "for key in required_keys:\n",
        "    # Verifica se a chave n√£o existe ou se o valor √© vazio\n",
        "    if not secrets.get(key):\n",
        "        print(f\"ü§î O segredo '{key}' n√£o foi encontrado ou est√° vazio no arquivo {SECRETS_PATH}.\")\n",
        "        # Solicita a chave usando getpass para entrada segura (n√£o exibe o texto digitado)\n",
        "        secrets[key] = getpass(f'üëâ Digite o valor para \"{key}\": ').strip()\n",
        "\n",
        "# Salva os segredos atualizados de volta no arquivo JSON no Drive\n",
        "save_secrets(secrets, SECRETS_PATH)\n",
        "print(f\"‚úÖ Segredos salvos/atualizados em {SECRETS_PATH}.\")\n",
        "\n",
        "# Define as vari√°veis de ambiente com os segredos carregados/solicitados\n",
        "for key, value in secrets.items():\n",
        "    os.environ[key] = value\n",
        "print(\"‚úÖ Vari√°veis de ambiente para segredos configuradas.\")\n",
        "\n",
        "# --- Parte de Autentica√ß√£o e Configura√ß√£o de Ferramentas ---\n",
        "\n",
        "# 4. Login Weights & Biases (Agora que WANDB_API_KEY deve estar no ambiente)\n",
        "# Tenta autenticar com a chave W&B carregada/solicitada\n",
        "wandb_api_key = os.environ.get('WANDB_API_KEY')\n",
        "if wandb_api_key and len(wandb_api_key) >= 40: # Verifica se a chave parece v√°lida (W&B API keys geralmente t√™m 40 caracteres, mas a valida√ß√£o completa √© feita pelo wandb.login)\n",
        "    try:\n",
        "        print(\"‚è≥ Tentando autenticar no Weights & Biases...\")\n",
        "        wandb.login(key=wandb_api_key, relogin=True) # relogin=True pode ajudar em alguns ambientes\n",
        "        print(\"‚úÖ Weights & Biases autenticado com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Falha ao autenticar Weights & Biases com a chave fornecida: {e}\")\n",
        "        print(\"‚ö†Ô∏è Verifique sua WANDB_API_KEY.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WANDB_API_KEY n√£o encontrado ou inv√°lido. Pulando autentica√ß√£o W&B.\")\n",
        "\n",
        "\n",
        "# 5. Instalar Depend√™ncias com Cache\n",
        "print(\"üì¶ Instalando depend√™ncias...\")\n",
        "# Lista de bibliotecas essenciais\n",
        "dependencies = \"pymupdf transformers datasets accelerate bitsandbytes wandb\"\n",
        "# Instala as depend√™ncias, usando um diret√≥rio de cache tempor√°rio para acelerar\n",
        "os.system(f\"pip install --quiet --cache-dir=/tmp/pip-cache {dependencies}\")\n",
        "print(f\"‚úÖ Depend√™ncias instaladas: {dependencies}\")\n",
        "\n",
        "# 6. Configurar accelerate\n",
        "print(\"‚öô Configurando accelerate...\")\n",
        "# Executa a configura√ß√£o padr√£o do accelerate (interativamente, mas 'yes' responde sim para todas as perguntas)\n",
        "# Redireciona a sa√≠da para /dev/null para evitar poluir a sa√≠da do notebook\n",
        "os.system(\"yes '' | accelerate config default > /dev/null 2>&1\")\n",
        "\n",
        "# Modifica o arquivo de configura√ß√£o do accelerate para habilitar mixed precision e aumentar accumulation steps\n",
        "cfg_path = 'accelerate_config.yaml'\n",
        "if os.path.exists(cfg_path):\n",
        "    try:\n",
        "        with open(cfg_path, 'r') as f:\n",
        "            config_content = f.read()\n",
        "\n",
        "        # Faz as substitui√ß√µes para habilitar fp16 e bf16 e aumentar gradient_accumulation_steps\n",
        "        config_content = config_content.replace('fp16: false', 'fp16: true')\n",
        "        config_content = config_content.replace('bf16: false', 'bf16: true')\n",
        "        config_content = config_content.replace('gradient_accumulation_steps: 1', 'gradient_accumulation_steps: 4')\n",
        "\n",
        "        with open(cfg_path, 'w') as f:\n",
        "            f.write(config_content)\n",
        "        print(\"‚öô accelerate configurado para fp16/bf16 & gradient_accumulation_steps=4\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Falha ao modificar o arquivo accelerate_config.yaml: {e}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Arquivo de configura√ß√£o do accelerate '{cfg_path}' n√£o encontrado ap√≥s a execu√ß√£o do comando 'accelerate config default'.\")\n",
        "\n",
        "\n",
        "# Opcional: Gerar link para o notebook atualizado (√∫til se estiver usando o Colab)\n",
        "try:\n",
        "    from google.colab import output\n",
        "    # Obt√©m o URL do notebook atual via JavaScript no ambiente Colab\n",
        "    notebook_link = output.eval_js(\"window.location.href\")\n",
        "    # Exibe o link como HTML clic√°vel\n",
        "    display(HTML(f'<a href=\"{notebook_link}\" target=\"_blank\">üîó Abrir este notebook em uma nova aba</a>'))\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è N√£o foi poss√≠vel gerar o link do notebook: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Configura√ß√£o de ambiente e gerenciamento de segredos conclu√≠dos!\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "4fcFj6vAcOdx",
        "outputId": "3d093feb-7df3-4081-8496-4368d3cedabc"
      },
      "id": "4fcFj6vAcOdx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Verificando recursos de hardware...\n",
            "‚úÖ GPU: Tesla T4, Mem√≥ria Aproximada: ~25GB\n",
            "‚è≥ Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive montado ou j√° conectado.\n",
            "üìÇ Caminho raiz dos dados (DATA_ROOT): /content/drive/MyDrive/med-llm/data\n",
            "‚úÖ Diret√≥rios de cache locais criados/verificados: ['/content/data/pdf_texts', '/content/data/datasets', '/content/data/models']\n",
            "üîë Verificando e configurando segredos...\n",
            "ü§î O segredo 'UMLS_API_KEY' n√£o foi encontrado ou est√° vazio no arquivo /content/drive/MyDrive/secrets.json.\n",
            "üëâ Digite o valor para \"UMLS_API_KEY\": ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Segredos salvos/atualizados em /content/drive/MyDrive/secrets.json.\n",
            "‚úÖ Vari√°veis de ambiente para segredos configuradas.\n",
            "‚è≥ Tentando autenticar no Weights & Biases...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrmatheuscoelho\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Weights & Biases autenticado com sucesso.\n",
            "üì¶ Instalando depend√™ncias...\n",
            "‚úÖ Depend√™ncias instaladas: pymupdf transformers datasets accelerate bitsandbytes wandb\n",
            "‚öô Configurando accelerate...\n",
            "‚ö†Ô∏è Arquivo de configura√ß√£o do accelerate 'accelerate_config.yaml' n√£o encontrado ap√≥s a execu√ß√£o do comando 'accelerate config default'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"https://8e4nnmrvp8r-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab_20250514-060044_RC00_758624382\" target=\"_blank\">üîó Abrir este notebook em uma nova aba</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Configura√ß√£o de ambiente e gerenciamento de segredos conclu√≠dos!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}